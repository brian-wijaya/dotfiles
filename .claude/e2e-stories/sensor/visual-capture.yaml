# Sensor Visual Capture — Stories and Constraints
# Format discovery findings, two-phase retrieval, API limits

vocabulary:
  text-briefing: Structured text incident report (~80-120 tokens) generated by sensor OCR pipeline. Dominates all image formats for information extraction.
  hybrid-format: Text briefing + micro thumbnails (~261 tokens). Optimal default for incidents requiring both textual content and visual navigation.
  two-phase-retrieval: Cheap index phase (text + thumbnails) identifies what to examine, then selective full-res retrieval on demand. Avoids paying full-res cost for all captured data.
  micro-thumbnail: Separate small image (~24 tokens each) addressable by index. Not a contact sheet — individual images that Claude can reference by number.
  per-image-overhead: ~2 tokens per image (vision encoder start/end markers). Negligible at N<50.
  many-image-limit: Claude API dynamic constraint — max image dimension drops to 2000px when conversation contains many images. Exceeding this poisons the conversation permanently.

metadata:
  feature: sensor
  component: visual-capture
  tags: [sensor, visual, capture, format, empirical]

stories:
  # === FORMAT SELECTION ===

  - name: text-briefing-default
    description: >
      Text-only incident briefings are the default format for all visual events.
      Empirically validated: 5.0/5 accuracy at ~237 tokens vs best image format
      4.0/5 at ~1178 tokens. Text-as-text is permanently more efficient than
      text-as-pixels — the ratio holds for any model architecture.
    preconditions:
      - sensor visual pipeline running with OCR
    steps:
      - screen change detected by tier 0 watchdog
      - tier 1 structural capture triggers OCR
      - incident briefing generated as structured text
    verify:
      - briefing contains all text content from changed region
      - token cost is ~80-120 tokens
      - no image sent unless visual judgment is needed

  - name: hybrid-format-for-navigation
    description: >
      When Claude needs to choose which region to examine at full resolution,
      the hybrid format (text briefing + micro thumbnails) provides both
      textual content AND visual navigation at ~261 tokens total.
    preconditions:
      - multiple visual events in buffer
    steps:
      - kinetic assembles hybrid: text briefing + indexed micro thumbnails
      - Claude reads text, identifies interesting region by thumbnail index
      - Claude requests tier 2 full-res crop of selected region
    verify:
      - Claude can identify the correct region from thumbnails
      - full-res crop delivered only for requested region
      - total cost is hybrid (~261) + one tier 2 crop (~300-1500)

  - name: two-phase-retrieval
    description: >
      Visual data access follows two phases: cheap index (text + thumbnails)
      for browsing, then selective full-res retrieval for the specific regions
      Claude needs. This avoids paying full-res token cost for all captured data.
    steps:
      - Phase 1: Claude receives text briefing + thumbnail strip of last 30s
      - Phase 1: Claude identifies frames/regions of interest
      - Phase 2: Claude requests tier 2 crops of specific frames/regions
    verify:
      - Phase 1 cost is ~261 tokens regardless of how many frames captured
      - Phase 2 cost scales only with requested crops, not total captured

  # === IMAGE SIZE AND COUNT BEHAVIOR ===

  - name: per-image-overhead-constant
    description: >
      Each image in Claude's context costs ~2 tokens of overhead (vision encoder
      start/end markers) regardless of image dimensions. At N<50 images, this
      overhead is negligible. Quality does not degrade with image count at N=10.
    steps:
      - send 1 image, observe token count
      - send 10 separate images, observe token count
      - send 10 images as single montage, observe token count
    verify:
      - per-image overhead is ~2 tokens
      - 10 separate images have ~20 tokens more overhead than 1 montage
      - accuracy identical between separate images and montage at N=10

  - name: no-quality-cliff-across-sizes
    description: >
      Claude's vision system has no quality cliff at any image size from 1x1
      through 2200x2200. A single red pixel is correctly identified. Text at
      14px on a 56x56 image is correctly read. Large images are downscaled
      but content remains accessible.
    steps:
      - send 1x1 colored pixel image
      - send 56x56 image with text "XRAY"
      - send 2200x2200 image with dense text
    verify:
      - 1x1 color correctly identified
      - 56x56 text correctly read
      - 2200x2200 text correctly read after downscale

  - name: separate-images-addressable
    description: >
      Separate images (not montages) give Claude addressability — "show me frame #7"
      is possible with separate images, not with a contact sheet. Both formats
      produce identical accuracy at N=10, but separate images enable selective
      retrieval in the two-phase architecture.
    steps:
      - send 10 separate micro thumbnails with index labels
      - ask Claude to identify content of frame #7
    verify:
      - Claude correctly identifies and references frame #7 by index
      - no confusion with adjacent frames

  # === API LIMITS ===

  - name: many-image-dimension-limit
    description: >
      The Claude API enforces a dynamic max image dimension that drops to 2000px
      when the conversation contains many images. Sending an image >2000px on any
      dimension after this threshold triggers a persistent 400 error that poisons
      the entire conversation — the failed image stays in message history and
      every subsequent turn fails.
    steps:
      - build up many images in conversation context
      - attempt to send a 3440px wide screenshot
    verify:
      - API returns 400 error about max dimension
      - subsequent turns also fail (conversation poisoned)
      - sending 1800px wide image in same context succeeds

enforced_constraints:
  - name: max-2000px-any-dimension
    description: >
      No image sent to Claude may exceed 2000px on any dimension when the
      conversation may contain many images. The visual pipeline must downscale
      all images to fit within 2000×2000 before sending.
    rationale: >
      The Claude API enforces this limit dynamically. Exceeding it poisons the
      entire conversation permanently — the oversized image stays in message
      history and every subsequent turn returns a 400 error. This was confirmed
      empirically: a 3440px screenshot killed a session, while 1800px succeeded.

  - name: text-before-pixels
    description: >
      For all text-extraction tasks, structured text (from OCR or API) is sent
      instead of images. Images are sent only when visual judgment is required
      (aesthetics, rendering bugs, unfamiliar UI). This is permanent — the
      information-theoretic efficiency of text-as-text vs text-as-pixels is a
      property of the encoding, not the decoder.
    rationale: >
      Empirically validated: text briefing scores 5.0/5 at ~237 tokens. Best
      image format scores 4.0/5 at ~1178 tokens. The ratio is 5× fewer tokens
      at equal or higher accuracy. See ADR-019 for the full analysis.

  - name: two-phase-retrieval-architecture
    description: >
      Visual data access always follows two phases: cheap index for browsing,
      selective full-res for examination. Never send all captured data at full
      resolution — the index phase identifies what's worth examining.
    rationale: >
      A 30-second capture at full resolution costs ~47,000 tokens. The index
      phase (text + thumbnails) costs ~261 tokens. Only the 1-3 regions Claude
      actually needs get full-res treatment. Total cost: ~261 + ~900 = ~1,161
      tokens vs 47,000. This is a 40× reduction.

opinionated_constraints:
  - name: separate-thumbnails-not-montage-for-index
    description: >
      The index phase uses separate micro thumbnails (addressable by index),
      not contact sheet montages. Contact sheets are used for temporal sequences
      in tier 1 structural capture (see ADR-018).
    rationale: >
      Separate thumbnails enable selective retrieval: "show me frame #7 at full
      resolution." Contact sheets lose addressability — Claude can describe
      what's in the 3rd row, 2nd column, but can't request a specific frame.
      The per-image overhead (~2 tokens each) is negligible.

  - name: hybrid-over-pure-text-for-navigation
    description: >
      When Claude needs to choose which region to examine, hybrid format
      (text + thumbnails) is preferred over pure text. Thumbnails provide
      spatial/visual context that text descriptions cannot capture.
    rationale: >
      Pure text is optimal for extraction (5.0/5). But when Claude needs to
      navigate multiple visual events and decide which to examine, thumbnails
      add visual context at marginal cost (+24 tokens). The hybrid format
      scored 5.0/5 at ~261 tokens — same accuracy as pure text with better
      navigation support.
