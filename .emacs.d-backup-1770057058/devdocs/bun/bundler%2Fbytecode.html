<h1 id="header">Bytecode Caching</h1>
<div data-page-title="Bytecode Caching" data-page-href="/bundler/bytecode" id="content">
<span data-as="p">Bytecode caching is a build-time optimization that dramatically improves application startup time by pre-compiling your JavaScript to bytecode. For example, when compiling TypeScript’s <code>tsc</code> with bytecode enabled, startup time improves by <strong>2x</strong>.</span> <h2 id="usage"><span>Usage</span></h2> <h3 id="basic-usage"><span>Basic usage</span></h3> <span data-as="p">Enable bytecode caching with the <code>--bytecode</code> flag:</span> <pre numberoflines="1" language="shellscript" data-language="typescript">bun build ./index.ts --target=bun --bytecode --outdir=./dist
</pre> <span data-as="p">This generates two files:</span> <ul> <li>
<code>dist/index.js</code> - Your bundled JavaScript</li> <li>
<code>dist/index.jsc</code> - The bytecode cache file</li> </ul> <span data-as="p">At runtime, Bun automatically detects and uses the <code>.jsc</code> file:</span> <pre numberoflines="1" language="shellscript" data-language="typescript">bun ./dist/index.js  # Automatically uses index.jsc
</pre> <h3 id="with-standalone-executables"><span>With standalone executables</span></h3> <span data-as="p">When creating executables with <code>--compile</code>, bytecode is embedded into the binary:</span> <pre numberoflines="1" language="shellscript" data-language="typescript">bun build ./cli.ts --compile --bytecode --outfile=mycli
</pre> <span data-as="p">The resulting executable contains both the code and bytecode, giving you maximum performance in a single file.</span> <h3 id="combining-with-other-optimizations"><span>Combining with other optimizations</span></h3> <span data-as="p">Bytecode works great with minification and source maps:</span> <pre numberoflines="1" language="shellscript" data-language="typescript">bun build --compile --bytecode --minify --sourcemap ./cli.ts --outfile=mycli
</pre> <ul> <li>
<code>--minify</code> reduces code size before generating bytecode (less code -&gt; less bytecode)</li> <li>
<code>--sourcemap</code> preserves error reporting (errors still point to original source)</li> <li>
<code>--bytecode</code> eliminates parsing overhead</li> </ul> <h2 id="performance-impact"><span>Performance impact</span></h2> <span data-as="p">The performance improvement scales with your codebase size:</span> <div data-table-wrapper="true"><div><table> <thead><tr>
<th>Application size</th>
<th>Typical startup improvement</th>
</tr></thead> <tbody>
<tr>
<td>Small CLI (&lt; 100 KB)</td>
<td>1.5-2x faster</td>
</tr>
<tr>
<td>Medium-large app (&gt; 5 MB)</td>
<td>2.5x-4x faster</td>
</tr>
</tbody> </table></div></div> <span data-as="p">Larger applications benefit more because they have more code to parse.</span> <h2 id="when-to-use-bytecode"><span>When to use bytecode</span></h2> <h3 id="great-for:"><span>Great for:</span></h3> <h4 id="cli-tools"><span>CLI tools</span></h4> <ul> <li>Invoked frequently (linters, formatters, git hooks)</li> <li>Startup time is the entire user experience</li> <li>Users notice the difference between 90ms and 45ms startup</li> <li>Example: TypeScript compiler, Prettier, ESLint</li> </ul> <h4 id="build-tools-and-task-runners"><span>Build tools and task runners</span></h4> <ul> <li>Run hundreds or thousands of times during development</li> <li>Milliseconds saved per run compound quickly</li> <li>Developer experience improvement</li> <li>Example: Build scripts, test runners, code generators</li> </ul> <h4 id="standalone-executables"><span>Standalone executables</span></h4> <ul> <li>Distributed to users who care about snappy performance</li> <li>Single-file distribution is convenient</li> <li>File size less important than startup time</li> <li>Example: CLIs distributed via npm or as binaries</li> </ul> <h3 id="skip-it-for:"><span>Skip it for:</span></h3> <ul> <li>❌ <strong>Small scripts</strong>
</li> <li>❌ <strong>Code that runs once</strong>
</li> <li>❌ <strong>Development builds</strong>
</li> <li>❌ <strong>Size-constrained environments</strong>
</li> <li>❌ <strong>Code with top-level await</strong> (not supported)</li> </ul> <h2 id="limitations"><span>Limitations</span></h2> <h3 id="commonjs-only"><span>CommonJS only</span></h3> <span data-as="p">Bytecode caching currently works with CommonJS output format. Bun’s bundler automatically converts most ESM code to CommonJS, but <strong>top-level await</strong> is the exception:</span> <pre numberoflines="3" language="javascript" data-language="typescript">// This prevents bytecode caching
const data = await fetch("https://api.example.com");
export default data;
</pre> <span data-as="p"><strong>Why</strong>: Top-level await requires async module evaluation, which can’t be represented in CommonJS. The module graph becomes asynchronous, and the CommonJS wrapper function model breaks down.</span> <span data-as="p"><strong>Workaround</strong>: Move async initialization into a function:</span> <pre numberoflines="6" language="javascript" data-language="typescript">async function init() {
  const data = await fetch("https://api.example.com");
  return data;
}

export default init;
</pre> <span data-as="p">Now the module exports a function that the consumer can await when needed.</span> <h3 id="version-compatibility"><span>Version compatibility</span></h3> <span data-as="p">Bytecode is <strong>not portable across Bun versions</strong>. The bytecode format is tied to JavaScriptCore’s internal representation, which changes between versions.</span> <span data-as="p">When you update Bun, you must regenerate bytecode:</span> <pre numberoflines="2" language="shellscript" data-language="typescript"># After updating Bun
bun build --bytecode ./index.ts --outdir=./dist
</pre> <span data-as="p">If bytecode doesn’t match the current Bun version, it’s automatically ignored and your code falls back to parsing the JavaScript source. Your app still runs - you just lose the performance optimization.</span> <span data-as="p"><strong>Best practice</strong>: Generate bytecode as part of your CI/CD build process. Don’t commit <code>.jsc</code> files to git. Regenerate them whenever you update Bun.</span> <h3 id="source-code-still-required"><span>Source code still required</span></h3> <ul> <li>The <code>.js</code> file (your bundled source code)</li> <li>The <code>.jsc</code> file (the bytecode cache)</li> </ul> <span data-as="p">At runtime:</span> <ol> <li>Bun loads the <code>.js</code> file, sees a <code>@bytecode</code> pragma, and checks the <code>.jsc</code> file</li> <li>Bun loads the <code>.jsc</code> file</li> <li>Bun validates the bytecode hash matches the source</li> <li>If valid, Bun uses the bytecode</li> <li>If invalid, Bun falls back to parsing the source</li> </ol> <h3 id="bytecode-is-not-obfuscation"><span>Bytecode is not obfuscation</span></h3> <span data-as="p">Bytecode <strong>does not obscure your source code</strong>. It’s an optimization, not a security measure.</span> <h2 id="production-deployment"><span>Production deployment</span></h2> <h3 id="docker"><span>Docker</span></h3> <span data-as="p">Include bytecode generation in your Dockerfile:</span> <pre numberoflines="16" language="docker" data-language="typescript">FROM oven/bun:1 AS builder
WORKDIR /app
COPY package.json bun.lock ./
RUN bun install --frozen-lockfile

COPY . .
RUN bun build --bytecode --minify --sourcemap \
  --target=bun \
  --outdir=./dist \
  --compile \
  ./src/server.ts --outfile=./dist/server

FROM oven/bun:1 AS runner
WORKDIR /app
COPY --from=builder /dist/server /app/server
CMD ["./server"]
</pre> <span data-as="p">The bytecode is architecture-independent.</span> <h3 id="ci/cd"><span>CI/CD</span></h3> <span data-as="p">Generate bytecode during your build pipeline:</span> <pre numberoflines="8" language="yaml" data-language="typescript"># GitHub Actions
- name: Build with bytecode
  run: |
    bun install
    bun build --bytecode --minify \
      --outdir=./dist \
      --target=bun \
      ./src/index.ts
</pre> <h2 id="debugging"><span>Debugging</span></h2> <h3 id="verify-bytecode-is-being-used"><span>Verify bytecode is being used</span></h3> <span data-as="p">Check that the <code>.jsc</code> file exists:</span> <pre numberoflines="1" language="shellscript" data-language="typescript">ls -lh dist/
</pre> <pre numberoflines="3" language="text" data-language="typescript">-rw-r--r--  1 user  staff   245K  index.js
-rw-r--r--  1 user  staff   1.1M  index.jsc
</pre> <span data-as="p">The <code>.jsc</code> file should be 2-8x larger than the <code>.js</code> file.</span> <span data-as="p">To log if bytecode is being used, set <code>BUN_JSC_verboseDiskCache=1</code> in your environment.</span> <span data-as="p">On success, it will log something like:</span> <pre numberoflines="2" language="text" data-language="typescript">[Disk cache] cache hit for sourceCode
</pre> <span data-as="p">If you see a cache miss, it will log something like:</span> <pre numberoflines="2" language="text" data-language="typescript">[Disk cache] cache miss for sourceCode
</pre> <span data-as="p">It’s normal for it it to log a cache miss multiple times since Bun doesn’t currently bytecode cache JavaScript code used in builtin modules.</span> <h3 id="common-issues"><span>Common issues</span></h3> <span data-as="p"><strong>Bytecode silently ignored</strong>: Usually caused by a Bun version update. The cache version doesn’t match, so bytecode is rejected. Regenerate to fix.</span> <span data-as="p"><strong>File size too large</strong>: This is expected. Consider:</span> <ul> <li>Using <code>--minify</code> to reduce code size before bytecode generation</li> <li>Compressing <code>.jsc</code> files for network transfer (gzip/brotli)</li> <li>Evaluating if the startup performance gain is worth the size increase</li> </ul> <span data-as="p"><strong>Top-level await</strong>: Not supported. Refactor to use async initialization functions.</span> <h2 id="what-is-bytecode"><span>What is bytecode?</span></h2> <span data-as="p">When you run JavaScript, the JavaScript engine doesn’t execute your source code directly. Instead, it goes through several steps:</span> <ol> <li>
<strong>Parsing</strong>: The engine reads your JavaScript source code and converts it into an Abstract Syntax Tree (AST)</li> <li>
<strong>Bytecode compilation</strong>: The AST is compiled into bytecode - a lower-level representation that’s faster to execute</li> <li>
<strong>Execution</strong>: The bytecode is executed by the engine’s interpreter or JIT compiler</li> </ol> <span data-as="p">Bytecode is an intermediate representation - it’s lower-level than JavaScript source code, but higher-level than machine code. Think of it as assembly language for a virtual machine. Each bytecode instruction represents a single operation like “load this variable,” “add two numbers,” or “call this function.”</span> <span data-as="p">This happens <strong>every single time</strong> you run your code. If you have a CLI tool that runs 100 times a day, your code gets parsed 100 times. If you have a serverless function with frequent cold starts, parsing happens on every cold start.</span> <span data-as="p">With bytecode caching, Bun moves steps 1 and 2 to the build step. At runtime, the engine loads the pre-compiled bytecode and jumps straight to execution.</span> <h3 id="why-lazy-parsing-makes-this-even-better"><span>Why lazy parsing makes this even better</span></h3> <span data-as="p">Modern JavaScript engines use a clever optimization called <strong>lazy parsing</strong>. They don’t parse all your code upfront - instead, functions are only parsed when they’re first called:</span> <pre numberoflines="10" language="javascript" data-language="typescript">// Without bytecode caching:
function rarely_used() {
  // This 500-line function is only parsed
  // when it's actually called
}

function main() {
  console.log("Starting app");
  // rarely_used() is never called, so it's never parsed
}
</pre> <span data-as="p">This means parsing overhead isn’t just a startup cost - it happens throughout your application’s lifetime as different code paths execute. With bytecode caching, <strong>all functions are pre-compiled</strong>, even the ones that are lazily parsed. The parsing work happens once at build time instead of being distributed throughout your application’s execution.</span> <h2 id="the-bytecode-format"><span>The bytecode format</span></h2> <h3 id="inside-a-jsc-file"><span>Inside a .jsc file</span></h3> <span data-as="p">A <code>.jsc</code> file contains a serialized bytecode structure. Understanding what’s inside helps explain both the performance benefits and the file size tradeoff.</span> <span data-as="p"><strong>Header section</strong> (validated on every load):</span> <ul> <li>
<strong>Cache version</strong>: A hash tied to the JavaScriptCore framework version. This ensures bytecode generated with one version of Bun only runs with that exact version.</li> <li>
<strong>Code block type tag</strong>: Identifies whether this is a Program, Module, Eval, or Function code block.</li> </ul> <span data-as="p"><strong>SourceCodeKey</strong> (validates bytecode matches source):</span> <ul> <li>
<strong>Source code hash</strong>: A hash of the original JavaScript source code. Bun verifies this matches before using the bytecode.</li> <li>
<strong>Source code length</strong>: The exact length of the source, for additional validation.</li> <li>
<strong>Compilation flags</strong>: Critical compilation context like strict mode, whether it’s a script vs module, eval context type, etc. The same source code compiled with different flags produces different bytecode.</li> </ul> <span data-as="p"><strong>Bytecode instructions</strong>:</span> <ul> <li>
<strong>Instruction stream</strong>: The actual bytecode opcodes - the compiled representation of your JavaScript. This is a variable-length sequence of bytecode instructions.</li> <li>
<strong>Metadata table</strong>: Each opcode has associated metadata - things like profiling counters, type hints, and execution counts (even if not yet populated).</li> <li>
<strong>Jump targets</strong>: Pre-computed addresses for control flow (if/else, loops, switch statements).</li> <li>
<strong>Switch tables</strong>: Optimized lookup tables for switch statements.</li> </ul> <span data-as="p"><strong>Constants and identifiers</strong>:</span> <ul> <li>
<strong>Constant pool</strong>: All literal values in your code - numbers, strings, booleans, null, undefined. These are stored as actual JavaScript values (JSValues) so they don’t need to be parsed from source at runtime.</li> <li>
<strong>Identifier table</strong>: All variable and function names used in the code. Stored as deduplicated strings.</li> <li>
<strong>Source code representation markers</strong>: Flags indicating how constants should be represented (as integers, doubles, big ints, etc.).</li> </ul> <span data-as="p"><strong>Function metadata</strong> (for each function in your code):</span> <ul> <li>
<strong>Register allocation</strong>: How many registers (local variables) the function needs - <code>thisRegister</code>, <code>scopeRegister</code>, <code>numVars</code>, <code>numCalleeLocals</code>, <code>numParameters</code>.</li> <li>
<strong>Code features</strong>: A bitmask of function characteristics: is it a constructor? an arrow function? does it use <code>super</code>? does it have tail calls? These affect how the function is executed.</li> <li>
<strong>Lexically scoped features</strong>: Strict mode and other lexical context.</li> <li>
<strong>Parse mode</strong>: The mode in which the function was parsed (normal, async, generator, async generator).</li> </ul> <span data-as="p"><strong>Nested structures</strong>:</span> <ul> <li>
<strong>Function declarations and expressions</strong>: Each nested function gets its own bytecode block, recursively. A file with 100 functions has 100 separate bytecode blocks, all nested in the structure.</li> <li>
<strong>Exception handlers</strong>: Try/catch/finally blocks with their boundaries and handler addresses pre-computed.</li> <li>
<strong>Expression info</strong>: Maps bytecode positions back to source code locations for error reporting and debugging.</li> </ul> <h3 id="what-bytecode-does-not-contain"><span>What bytecode does NOT contain</span></h3> <span data-as="p">Importantly, <strong>bytecode does not embed your source code</strong>. Instead:</span> <ul> <li>The JavaScript source is stored separately (in the <code>.js</code> file)</li> <li>The bytecode only stores a hash and length of the source</li> <li>At load time, Bun validates the bytecode matches the current source code</li> </ul> <span data-as="p">This is why you need to deploy both the <code>.js</code> and <code>.jsc</code> files. The <code>.jsc</code> file is useless without its corresponding <code>.js</code> file.</span> <h2 id="the-tradeoff:-file-size"><span>The tradeoff: file size</span></h2> <span data-as="p">Bytecode files are significantly larger than source code - typically 2-8x larger.</span> <h3 id="why-is-bytecode-so-much-larger"><span>Why is bytecode so much larger?</span></h3> <span data-as="p"><strong>Bytecode instructions are verbose</strong>: A single line of minified JavaScript might compile to dozens of bytecode instructions. For example:</span> <pre numberoflines="1" language="javascript" data-language="typescript">const sum = arr.reduce((a, b) =&gt; a + b, 0);
</pre> <span data-as="p">Compiles to bytecode that:</span> <ul> <li>Loads the <code>arr</code> variable</li> <li>Gets the <code>reduce</code> property</li> <li>Creates the arrow function (which itself has bytecode)</li> <li>Loads the initial value <code>0</code>
</li> <li>Sets up the call with the right number of arguments</li> <li>Actually performs the call</li> <li>Stores the result in <code>sum</code>
</li> </ul> <span data-as="p">Each of these steps is a separate bytecode instruction with its own metadata.</span> <span data-as="p"><strong>Constant pools store everything</strong>: Every string literal, number, property name - everything gets stored in the constant pool. Even if your source code has <code>"hello"</code> a hundred times, the constant pool stores it once, but the identifier table and constant references add overhead.</span> <span data-as="p"><strong>Per-function metadata</strong>: Each function - even small one-line functions - gets its own complete metadata:</span> <ul> <li>Register allocation info</li> <li>Code features bitmask</li> <li>Parse mode</li> <li>Exception handlers</li> <li>Expression info for debugging</li> </ul> <span data-as="p">A file with 1,000 small functions has 1,000 sets of metadata.</span> <span data-as="p"><strong>Profiling data structures</strong>: Even though profiling data isn’t populated yet, the <em>structures</em> to hold profiling data are allocated. This includes:</span> <ul> <li>Value profile slots (tracking what types flow through each operation)</li> <li>Array profile slots (tracking array access patterns)</li> <li>Binary arithmetic profile slots (tracking number types in math operations)</li> <li>Unary arithmetic profile slots</li> </ul> <span data-as="p">These take up space even when empty.</span> <span data-as="p"><strong>Pre-computed control flow</strong>: Jump targets, switch tables, and exception handler boundaries are all pre-computed and stored. This makes execution faster but increases file size.</span> <h3 id="mitigation-strategies"><span>Mitigation strategies</span></h3> <span data-as="p"><strong>Compression</strong>: Bytecode compresses extremely well with gzip/brotli (60-70% compression). The repetitive structure and metadata compress efficiently.</span> <span data-as="p"><strong>Minification first</strong>: Using <code>--minify</code> before bytecode generation helps:</span> <ul> <li>Shorter identifiers → smaller identifier table</li> <li>Dead code elimination → less bytecode generated</li> <li>Constant folding → fewer constants in the pool</li> </ul> <span data-as="p"><strong>The tradeoff</strong>: You’re trading 2-4x larger files for 2-4x faster startup. For CLIs, this is usually worth it. For long-running servers where a few megabytes of disk space don’t matter, it’s even less of an issue.</span> <h2 id="versioning-and-portability"><span>Versioning and portability</span></h2> <h3 id="cross-architecture-portability:-✅"><span>Cross-architecture portability: ✅</span></h3> <span data-as="p">Bytecode is <strong>architecture-independent</strong>. You can:</span> <ul> <li>Build on macOS ARM64, deploy to Linux x64</li> <li>Build on Linux x64, deploy to AWS Lambda ARM64</li> <li>Build on Windows x64, deploy to macOS ARM64</li> </ul> <span data-as="p">The bytecode contains abstract instructions that work on any architecture. Architecture-specific optimizations happen during JIT compilation at runtime, not in the cached bytecode.</span> <h3 id="cross-version-portability:-❌"><span>Cross-version portability: ❌</span></h3> <span data-as="p">Bytecode is <strong>not stable across Bun versions</strong>. Here’s why:</span> <span data-as="p"><strong>Bytecode format changes</strong>: JavaScriptCore’s bytecode format evolves. New opcodes get added, old ones get removed or changed, metadata structures change. Each version of JavaScriptCore has a different bytecode format.</span> <span data-as="p"><strong>Version validation</strong>: The cache version in the <code>.jsc</code> file header is a hash of the JavaScriptCore framework. When Bun loads bytecode:</span> <ol> <li>It extracts the cache version from the <code>.jsc</code> file</li> <li>It computes the current JavaScriptCore version</li> <li>If they don’t match, the bytecode is <strong>silently rejected</strong>
</li> <li>Bun falls back to parsing the <code>.js</code> source code</li> </ol> <span data-as="p">Your application still runs - you just lose the performance optimization.</span> <span data-as="p"><strong>Graceful degradation</strong>: This design means bytecode caching “fails open” - if anything goes wrong (version mismatch, corrupted file, missing file), your code still runs normally. You might see slower startup, but you won’t see errors.</span> <h2 id="unlinked-vs-linked-bytecode"><span>Unlinked vs. linked bytecode</span></h2> <span data-as="p">JavaScriptCore makes a crucial distinction between “unlinked” and “linked” bytecode. This separation is what makes bytecode caching possible:</span> <h3 id="unlinked-bytecode-what’s-cached"><span>Unlinked bytecode (what’s cached)</span></h3> <span data-as="p">The bytecode saved in <code>.jsc</code> files is <strong>unlinked bytecode</strong>. It contains:</span> <ul> <li>The compiled bytecode instructions</li> <li>Structural information about the code</li> <li>Constants and identifiers</li> <li>Control flow information</li> </ul> <span data-as="p">But it <strong>doesn’t</strong> contain:</span> <ul> <li>Pointers to actual runtime objects</li> <li>JIT-compiled machine code</li> <li>Profiling data from previous runs</li> <li>Call link information (which functions call which)</li> </ul> <span data-as="p">Unlinked bytecode is <strong>immutable and shareable</strong>. Multiple executions of the same code can all reference the same unlinked bytecode.</span> <h3 id="linked-bytecode-runtime-execution"><span>Linked bytecode (runtime execution)</span></h3> <span data-as="p">When Bun runs bytecode, it “links” it - creating a runtime wrapper that adds:</span> <ul> <li>
<strong>Call link information</strong>: As your code runs, the engine learns which functions call which and optimizes those call sites.</li> <li>
<strong>Profiling data</strong>: The engine tracks how many times each instruction executes, what types of values flow through the code, array access patterns, etc.</li> <li>
<strong>JIT compilation state</strong>: References to baseline JIT or optimizing JIT (DFG/FTL) compiled versions of hot code.</li> <li>
<strong>Runtime objects</strong>: Pointers to actual JavaScript objects, prototypes, scopes, etc.</li> </ul> <span data-as="p">This linked representation is created fresh every time you run your code. This allows:</span> <ol> <li>
<strong>Caching the expensive work</strong> (parsing and compilation to unlinked bytecode)</li> <li>
<strong>Still collecting runtime profiling data</strong> to guide optimizations</li> <li>
<strong>Still applying JIT optimizations</strong> based on actual execution patterns</li> </ol> <span data-as="p">Bytecode caching moves expensive work (parsing and compiling to bytecode) from runtime to build time. For applications that start frequently, this can halve your startup time at the cost of larger files on disk.</span> <span data-as="p">For production CLIs and serverless deployments, the combination of <code>--bytecode --minify --sourcemap</code> gives you the best performance while maintaining debuggability.</span>
</div><div class="_attribution">
  <p class="_attribution-p">
    &copy; bun.com, oven-sh, Jarred Sumner<br>Licensed under the MIT License.<br>
    <a href="https://bun.com/docs/bundler/bytecode" class="_attribution-link">https://bun.com/docs/bundler/bytecode</a>
  </p>
</div>
