<h1 id="header">Fetch</h1>
<div data-page-title="Fetch" data-page-href="/runtime/networking/fetch" id="content">
<span data-as="p">Bun implements the WHATWG <code>fetch</code> standard, with some extensions to meet the needs of server-side JavaScript.</span> <span data-as="p">Bun also implements <code>node:http</code>, but <code>fetch</code> is generally recommended instead.</span> <h2 id="sending-an-http-request"><span>Sending an HTTP request</span></h2> <span data-as="p">To send an HTTP request, use <code>fetch</code></span> <pre numberoflines="5" language="typescript" data-language="typescript">const response = await fetch("http://example.com");

console.log(response.status); // =&gt; 200

const text = await response.text(); // or response.json(), response.formData(), etc.
</pre> <span data-as="p"><code>fetch</code> also works with HTTPS URLs.</span> <pre numberoflines="1" language="typescript" data-language="typescript">const response = await fetch("https://example.com");
</pre> <span data-as="p">You can also pass <code>fetch</code> a <a href="https://developer.mozilla.org/en-US/docs/Web/API/Request" target="_blank" rel="noreferrer"><code>Request</code></a> object.</span> <pre numberoflines="6" language="typescript" data-language="typescript">const request = new Request("http://example.com", {
  method: "POST",
  body: "Hello, world!",
});

const response = await fetch(request);
</pre> <h3 id="sending-a-post-request"><span>Sending a POST request</span></h3> <span data-as="p">To send a POST request, pass an object with the <code>method</code> property set to <code>"POST"</code>.</span> <pre numberoflines="4" language="typescript" data-language="typescript">const response = await fetch("http://example.com", {
  method: "POST",
  body: "Hello, world!",
});
</pre> <span data-as="p"><code>body</code> can be a string, a <code>FormData</code> object, an <code>ArrayBuffer</code>, a <code>Blob</code>, and more. See the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API/Using_Fetch#setting_a_body" target="_blank" rel="noreferrer">MDN documentation</a> for more information.</span> <h3 id="proxying-requests"><span>Proxying requests</span></h3> <span data-as="p">To proxy a request, pass an object with the <code>proxy</code> property set to a URL string:</span> <pre numberoflines="3" language="typescript" data-language="typescript">const response = await fetch("http://example.com", {
  proxy: "http://proxy.com",
});
</pre> <span data-as="p">You can also use an object format to send custom headers to the proxy server:</span> <pre numberoflines="9" language="typescript" data-language="typescript">const response = await fetch("http://example.com", {
  proxy: {
    url: "http://proxy.com",
    headers: {
      "Proxy-Authorization": "Bearer my-token",
      "X-Custom-Proxy-Header": "value",
    },
  },
});
</pre> <span data-as="p">The <code>headers</code> are sent directly to the proxy in <code>CONNECT</code> requests (for HTTPS targets) or in the proxy request (for HTTP targets). If you provide a <code>Proxy-Authorization</code> header, it overrides any credentials in the proxy URL.</span> <h3 id="custom-headers"><span>Custom headers</span></h3> <span data-as="p">To set custom headers, pass an object with the <code>headers</code> property set to an object.</span> <pre numberoflines="5" language="typescript" data-language="typescript">const response = await fetch("http://example.com", {
  headers: {
    "X-Custom-Header": "value",
  },
});
</pre> <span data-as="p">You can also set headers using the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Headers" target="_blank" rel="noreferrer">Headers</a> object.</span> <pre numberoflines="6" language="typescript" data-language="typescript">const headers = new Headers();
headers.append("X-Custom-Header", "value");

const response = await fetch("http://example.com", {
  headers,
});
</pre> <h3 id="response-bodies"><span>Response bodies</span></h3> <span data-as="p">To read the response body, use one of the following methods:</span> <ul> <li>
<code>response.text(): Promise&lt;string&gt;</code>: Returns a promise that resolves with the response body as a string.</li> <li>
<code>response.json(): Promise&lt;any&gt;</code>: Returns a promise that resolves with the response body as a JSON object.</li> <li>
<code>response.formData(): Promise&lt;FormData&gt;</code>: Returns a promise that resolves with the response body as a <code>FormData</code> object.</li> <li>
<code>response.bytes(): Promise&lt;Uint8Array&gt;</code>: Returns a promise that resolves with the response body as a <code>Uint8Array</code>.</li> <li>
<code>response.arrayBuffer(): Promise&lt;ArrayBuffer&gt;</code>: Returns a promise that resolves with the response body as an <code>ArrayBuffer</code>.</li> <li>
<code>response.blob(): Promise&lt;Blob&gt;</code>: Returns a promise that resolves with the response body as a <code>Blob</code>.</li> </ul> <h4 id="streaming-response-bodies"><span>Streaming response bodies</span></h4> <span data-as="p">You can use async iterators to stream the response body.</span> <pre numberoflines="5" language="typescript" data-language="typescript">const response = await fetch("http://example.com");

for await (const chunk of response.body) {
  console.log(chunk);
}
</pre> <span data-as="p">You can also more directly access the <code>ReadableStream</code> object.</span> <pre numberoflines="6" language="typescript" data-language="typescript">const response = await fetch("http://example.com");

const stream = response.body;

const reader = stream.getReader();
const { value, done } = await reader.read();
</pre> <h3 id="streaming-request-bodies"><span>Streaming request bodies</span></h3> <span data-as="p">You can also stream data in request bodies using a <code>ReadableStream</code>:</span> <pre numberoflines="13" language="typescript" data-language="typescript">const stream = new ReadableStream({
  start(controller) {
    controller.enqueue("Hello");
    controller.enqueue(" ");
    controller.enqueue("World");
    controller.close();
  },
});

const response = await fetch("http://example.com", {
  method: "POST",
  body: stream,
});
</pre> <span data-as="p">When using streams with HTTP(S):</span> <ul> <li>The data is streamed directly to the network without buffering the entire body in memory</li> <li>If the connection is lost, the stream will be canceled</li> <li>The <code>Content-Length</code> header is not automatically set unless the stream has a known size</li> </ul> <span data-as="p">When using streams with S3:</span> <ul> <li>For PUT/POST requests, Bun automatically uses multipart upload</li> <li>The stream is consumed in chunks and uploaded in parallel</li> <li>Progress can be monitored through the S3 options</li> </ul> <h3 id="fetching-a-url-with-a-timeout"><span>Fetching a URL with a timeout</span></h3> <span data-as="p">To fetch a URL with a timeout, use <code>AbortSignal.timeout</code>:</span> <pre numberoflines="3" language="typescript" data-language="typescript">const response = await fetch("http://example.com", {
  signal: AbortSignal.timeout(1000),
});
</pre> <h4 id="canceling-a-request"><span>Canceling a request</span></h4> <span data-as="p">To cancel a request, use an <code>AbortController</code>:</span> <pre numberoflines="7" language="typescript" data-language="typescript">const controller = new AbortController();

const response = await fetch("http://example.com", {
  signal: controller.signal,
});

controller.abort();
</pre> <h3 id="unix-domain-sockets"><span>Unix domain sockets</span></h3> <span data-as="p">To fetch a URL using a Unix domain socket, use the <code>unix: string</code> option:</span> <pre numberoflines="8" language="typescript" data-language="typescript">const response = await fetch("https://hostname/a/path", {
  unix: "/var/run/path/to/unix.sock",
  method: "POST",
  body: JSON.stringify({ message: "Hello from Bun!" }),
  headers: {
    "Content-Type": "application/json",
  },
});
</pre> <h3 id="tls"><span>TLS</span></h3> <span data-as="p">To use a client certificate, use the <code>tls</code> option:</span> <pre numberoflines="7" language="typescript" data-language="typescript">await fetch("https://example.com", {
  tls: {
    key: Bun.file("/path/to/key.pem"),
    cert: Bun.file("/path/to/cert.pem"),
    // ca: [Bun.file("/path/to/ca.pem")],
  },
});
</pre> <h4 id="custom-tls-validation"><span>Custom TLS Validation</span></h4> <span data-as="p">To customize the TLS validation, use the <code>checkServerIdentity</code> option in <code>tls</code></span> <pre numberoflines="7" language="typescript" data-language="typescript">await fetch("https://example.com", {
  tls: {
    checkServerIdentity: (hostname, peerCertificate) =&gt; {
      // Return an Error if the certificate is invalid
    },
  },
});
</pre> <span data-as="p">This is similar to how it works in Node’s <code>net</code> module.</span> <h4 id="disable-tls-validation"><span>Disable TLS validation</span></h4> <span data-as="p">To disable TLS validation, set <code>rejectUnauthorized</code> to <code>false</code>:</span> <pre numberoflines="5" language="typescript" data-language="typescript">await fetch("https://example.com", {
  tls: {
    rejectUnauthorized: false,
  },
});
</pre> <span data-as="p">This is especially useful to avoid SSL errors when using self-signed certificates, but this disables TLS validation and should be used with caution.</span> <h3 id="request-options"><span>Request options</span></h3> <span data-as="p">In addition to the standard fetch options, Bun provides several extensions:</span> <pre numberoflines="11" language="typescript" data-language="typescript">const response = await fetch("http://example.com", {
  // Control automatic response decompression (default: true)
  // Supports gzip, deflate, brotli (br), and zstd
  decompress: true,

  // Disable connection reuse for this request
  keepalive: false,

  // Debug logging level
  verbose: true, // or "curl" for more detailed output
});
</pre> <h3 id="protocol-support"><span>Protocol support</span></h3> <span data-as="p">Beyond HTTP(S), Bun’s fetch supports several additional protocols:</span> <h4 id="s3-urls-s3://"><span>S3 URLs - <code>s3://</code></span></h4> <span data-as="p">Bun supports fetching from S3 buckets directly.</span> <pre numberoflines="11" language="typescript" data-language="typescript">// Using environment variables for credentials
const response = await fetch("s3://my-bucket/path/to/object");

// Or passing credentials explicitly
const response = await fetch("s3://my-bucket/path/to/object", {
  s3: {
    accessKeyId: "YOUR_ACCESS_KEY",
    secretAccessKey: "YOUR_SECRET_KEY",
    region: "us-east-1",
  },
});
</pre> <span data-as="p">Note: Only PUT and POST methods support request bodies when using S3. For uploads, Bun automatically uses multipart upload for streaming bodies.</span> <span data-as="p">You can read more about Bun’s S3 support in the <a href="../s3">S3</a> documentation.</span> <h4 id="file-urls-file://"><span>File URLs - <code>file://</code></span></h4> <span data-as="p">You can fetch local files using the <code>file:</code> protocol:</span> <pre numberoflines="2" language="typescript" data-language="typescript">const response = await fetch("file:///path/to/file.txt");
const text = await response.text();
</pre> <span data-as="p">On Windows, paths are automatically normalized:</span> <pre numberoflines="3" language="typescript" data-language="typescript">// Both work on Windows
const response = await fetch("file:///C:/path/to/file.txt");
const response2 = await fetch("file:///c:/path\\to/file.txt");
</pre> <h4 id="data-urls-data:"><span>Data URLs - <code>data:</code></span></h4> <span data-as="p">Bun supports the <code>data:</code> URL scheme:</span> <pre numberoflines="2" language="typescript" data-language="typescript">const response = await fetch("data:text/plain;base64,SGVsbG8sIFdvcmxkIQ==");
const text = await response.text(); // "Hello, World!"
</pre> <h4 id="blob-urls-blob:"><span>Blob URLs - <code>blob:</code></span></h4> <span data-as="p">You can fetch blobs using URLs created by <code>URL.createObjectURL()</code>:</span> <pre numberoflines="3" language="typescript" data-language="typescript">const blob = new Blob(["Hello, World!"], { type: "text/plain" });
const url = URL.createObjectURL(blob);
const response = await fetch(url);
</pre> <h3 id="error-handling"><span>Error handling</span></h3> <span data-as="p">Bun’s fetch implementation includes several specific error cases:</span> <ul> <li>Using a request body with GET/HEAD methods will throw an error (which is expected for the fetch API)</li> <li>Attempting to use both <code>proxy</code> and <code>unix</code> options together will throw an error</li> <li>TLS certificate validation failures when <code>rejectUnauthorized</code> is true (or undefined)</li> <li>S3 operations may throw specific errors related to authentication or permissions</li> </ul> <h3 id="content-type-handling"><span>Content-Type handling</span></h3> <span data-as="p">Bun automatically sets the <code>Content-Type</code> header for request bodies when not explicitly provided:</span> <ul> <li>For <code>Blob</code> objects, uses the blob’s <code>type</code>
</li> <li>For <code>FormData</code>, sets appropriate multipart boundary</li> </ul> <h2 id="debugging"><span>Debugging</span></h2> <span data-as="p">To help with debugging, you can pass <code>verbose: true</code> to <code>fetch</code>:</span> <pre numberoflines="3" language="typescript" data-language="typescript">const response = await fetch("http://example.com", {
  verbose: true,
});
</pre> <span data-as="p">This will print the request and response headers to your terminal:</span> <pre numberoflines="20" language="shellscript" data-language="typescript">[fetch] &gt; HTTP/1.1 GET http://example.com/
[fetch] &gt; Connection: keep-alive
[fetch] &gt; User-Agent: Bun/1.3.3
[fetch] &gt; Accept: */*
[fetch] &gt; Host: example.com
[fetch] &gt; Accept-Encoding: gzip, deflate, br, zstd

[fetch] &lt; 200 OK
[fetch] &lt; Content-Encoding: gzip
[fetch] &lt; Age: 201555
[fetch] &lt; Cache-Control: max-age=604800
[fetch] &lt; Content-Type: text/html; charset=UTF-8
[fetch] &lt; Date: Sun, 21 Jul 2024 02:41:14 GMT
[fetch] &lt; Etag: "3147526947+gzip"
[fetch] &lt; Expires: Sun, 28 Jul 2024 02:41:14 GMT
[fetch] &lt; Last-Modified: Thu, 17 Oct 2019 07:18:26 GMT
[fetch] &lt; Server: ECAcc (sac/254F)
[fetch] &lt; Vary: Accept-Encoding
[fetch] &lt; X-Cache: HIT
[fetch] &lt; Content-Length: 648
</pre> <span data-as="p">Note: <code>verbose: boolean</code> is not part of the Web standard <code>fetch</code> API and is specific to Bun.</span> <h2 id="performance"><span>Performance</span></h2> <span data-as="p">Before an HTTP request can be sent, the DNS lookup must be performed. This can take a significant amount of time, especially if the DNS server is slow or the network connection is poor.</span> <span data-as="p">After the DNS lookup, the TCP socket must be connected and the TLS handshake might need to be performed. This can also take a significant amount of time.</span> <span data-as="p">After the request completes, consuming the response body can also take a significant amount of time and memory.</span> <span data-as="p">At every step of the way, Bun provides APIs to help you optimize the performance of your application.</span> <h3 id="dns-prefetching"><span>DNS prefetching</span></h3> <span data-as="p">To prefetch a DNS entry, you can use the <code>dns.prefetch</code> API. This API is useful when you know you’ll need to connect to a host soon and want to avoid the initial DNS lookup.</span> <pre numberoflines="3" language="typescript" data-language="typescript">import { dns } from "bun";

dns.prefetch("bun.com");
</pre> <h4 id="dns-caching"><span>DNS caching</span></h4> <span data-as="p">By default, Bun caches and deduplicates DNS queries in-memory for up to 30 seconds. You can see the cache stats by calling <code>dns.getCacheStats()</code>:</span> <span data-as="p">To learn more about DNS caching in Bun, see the <a href="dns">DNS caching</a> documentation.</span> <h3 id="preconnect-to-a-host"><span>Preconnect to a host</span></h3> <span data-as="p">To preconnect to a host, you can use the <code>fetch.preconnect</code> API. This API is useful when you know you’ll need to connect to a host soon and want to start the initial DNS lookup, TCP socket connection, and TLS handshake early.</span> <pre numberoflines="3" language="typescript" data-language="typescript">import { fetch } from "bun";

fetch.preconnect("https://bun.com");
</pre> <span data-as="p">Note: calling <code>fetch</code> immediately after <code>fetch.preconnect</code> will not make your request faster. Preconnecting only helps if you know you’ll need to connect to a host soon, but you’re not ready to make the request yet.</span> <h4 id="preconnect-at-startup"><span>Preconnect at startup</span></h4> <span data-as="p">To preconnect to a host at startup, you can pass <code>--fetch-preconnect</code>:</span> <pre numberoflines="1" language="shellscript" data-language="typescript">bun --fetch-preconnect https://bun.com ./my-script.ts
</pre> <span data-as="p">This is sort of like <code>&lt;link rel="preconnect"&gt;</code> in HTML.</span> <span data-as="p">This feature is not implemented on Windows yet. If you’re interested in using this feature on Windows, please file an issue and we can implement support for it on Windows.</span> <h3 id="connection-pooling-&amp;-http-keep-alive"><span>Connection pooling &amp; HTTP keep-alive</span></h3> <span data-as="p">Bun automatically reuses connections to the same host. This is known as connection pooling. This can significantly reduce the time it takes to establish a connection. You don’t need to do anything to enable this; it’s automatic.</span> <h4 id="simultaneous-connection-limit"><span>Simultaneous connection limit</span></h4> <span data-as="p">By default, Bun limits the maximum number of simultaneous <code>fetch</code> requests to 256. We do this for several reasons:</span> <ul> <li>It improves overall system stability. Operating systems have an upper limit on the number of simultaneous open TCP sockets, usually in the low thousands. Nearing this limit causes your entire computer to behave strangely. Applications hang and crash.</li> <li>It encourages HTTP Keep-Alive connection reuse. For short-lived HTTP requests, the slowest step is often the initial connection setup. Reusing connections can save a lot of time.</li> </ul> <span data-as="p">When the limit is exceeded, the requests are queued and sent as soon as the next request ends.</span> <span data-as="p">You can increase the maximum number of simultaneous connections via the <code>BUN_CONFIG_MAX_HTTP_REQUESTS</code> environment variable:</span> <pre numberoflines="1" language="shellscript" data-language="typescript">BUN_CONFIG_MAX_HTTP_REQUESTS=512 bun ./my-script.ts
</pre> <span data-as="p">The max value for this limit is currently set to 65,336. The maximum port number is 65,535, so it’s quite difficult for any one computer to exceed this limit.</span> <h3 id="response-buffering"><span>Response buffering</span></h3> <span data-as="p">Bun goes to great lengths to optimize the performance of reading the response body. The fastest way to read the response body is to use one of these methods:</span> <ul> <li><code>response.text(): Promise&lt;string&gt;</code></li> <li><code>response.json(): Promise&lt;any&gt;</code></li> <li><code>response.formData(): Promise&lt;FormData&gt;</code></li> <li><code>response.bytes(): Promise&lt;Uint8Array&gt;</code></li> <li><code>response.arrayBuffer(): Promise&lt;ArrayBuffer&gt;</code></li> <li><code>response.blob(): Promise&lt;Blob&gt;</code></li> </ul> <span data-as="p">You can also use <code>Bun.write</code> to write the response body to a file on disk:</span> <pre numberoflines="3" language="typescript" data-language="typescript">import { write } from "bun";

await write("output.txt", response);
</pre> <h3 id="implementation-details"><span>Implementation details</span></h3> <ul> <li>Connection pooling is enabled by default but can be disabled per-request with <code>keepalive: false</code>. The <code>"Connection: close"</code> header can also be used to disable keep-alive.</li> <li>Large file uploads are optimized using the operating system’s <code>sendfile</code> syscall under specific conditions: <ul> <li>The file must be larger than 32KB</li> <li>The request must not be using a proxy</li> <li>On macOS, only regular files (not pipes, sockets, or devices) can use <code>sendfile</code>
</li> <li>When these conditions aren’t met, or when using S3/streaming uploads, Bun falls back to reading the file into memory</li> <li>This optimization is particularly effective for HTTP (not HTTPS) requests where the file can be sent directly from the kernel to the network stack</li> </ul> </li> <li>S3 operations automatically handle signing requests and merging authentication headers</li> </ul> <span data-as="p">Note: Many of these features are Bun-specific extensions to the standard fetch API.</span>
</div><div class="_attribution">
  <p class="_attribution-p">
    &copy; bun.com, oven-sh, Jarred Sumner<br>Licensed under the MIT License.<br>
    <a href="https://bun.com/docs/runtime/networking/fetch" class="_attribution-link">https://bun.com/docs/runtime/networking/fetch</a>
  </p>
</div>
